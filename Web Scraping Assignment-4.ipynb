{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d49cddff",
   "metadata": {},
   "source": [
    "# 1.)Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url\n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A)\n",
    "Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "021d006e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\rahul\\anaconda3\\lib\\site-packages (4.17.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: idna in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\rahul\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f2f6f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb803fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome();\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e44619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = []\n",
    "Name=driver.find_elements(By.XPATH, \"(//table[contains(@class,'wikitable')])[1]/tbody/tr/td[1]/a\")\n",
    "for i in Name:\n",
    "    Name=i.text\n",
    "    NAME.append(Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "639d47c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baby Shark Dance',\n",
       " 'Despacito',\n",
       " 'Johny Johny Yes Papa',\n",
       " 'Bath Song',\n",
       " 'Shape of You',\n",
       " 'See You Again',\n",
       " 'Wheels on the Bus',\n",
       " 'Phonics Song with Two Words',\n",
       " 'Uptown Funk',\n",
       " 'Learning Colors – Colorful Eggs on a Farm',\n",
       " 'Gangnam Style',\n",
       " 'Dame Tu Cosita',\n",
       " 'Axel F',\n",
       " 'Sugar',\n",
       " 'Counting Stars',\n",
       " 'Baa Baa Black Sheep',\n",
       " 'Roar',\n",
       " 'Lakdi Ki Kathi',\n",
       " 'Waka Waka (This Time for Africa)',\n",
       " 'Sorry',\n",
       " 'Thinking Out Loud',\n",
       " 'Humpty the train on a fruits ride',\n",
       " 'Shree Hanuman Chalisa',\n",
       " 'Dark Horse',\n",
       " 'Perfect',\n",
       " 'Let Her Go',\n",
       " 'Faded',\n",
       " 'Girls Like You',\n",
       " 'Lean On']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a03636",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIST = []\n",
    "Artist=driver.find_elements(By.XPATH, \"(//table[contains(@class,'wikitable')])[1]/tbody/tr/td[2]\")\n",
    "for i in Artist:\n",
    "    Artist=i.text\n",
    "    ARTIST.append(Artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e339ecf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df164351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " 'Luis Fonsi',\n",
       " \"LooLoo Kids - Nursery Rhymes and Children's Songs\",\n",
       " 'Cocomelon - Nursery Rhymes',\n",
       " 'Ed Sheeran',\n",
       " 'Wiz Khalifa',\n",
       " 'Cocomelon - Nursery Rhymes',\n",
       " 'ChuChu TV Nursery Rhymes & Kids Songs',\n",
       " 'Mark Ronson',\n",
       " 'Miroshka TV',\n",
       " 'Psy',\n",
       " 'Get Movies',\n",
       " 'Ultra Records',\n",
       " 'Crazy Frog',\n",
       " 'Maroon 5',\n",
       " 'OneRepublic',\n",
       " 'Cocomelon - Nursery Rhymes',\n",
       " 'Katy Perry',\n",
       " 'Jingle Toons',\n",
       " 'Shakira',\n",
       " 'Justin Bieber',\n",
       " 'Ed Sheeran',\n",
       " 'Kiddiestv Hindi - Nursery Rhymes & Kids Songs',\n",
       " 'T-Series Bhakti Sagar',\n",
       " 'Katy Perry',\n",
       " 'Ed Sheeran',\n",
       " 'Passenger',\n",
       " 'Alan Walker',\n",
       " 'Maroon 5',\n",
       " 'Major Lazer Official']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARTIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f817eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = []\n",
    "Date=driver.find_elements(By.XPATH, \"(//table[contains(@class,'wikitable')])[1]/tbody/tr/td[4]\")\n",
    "for i in Date:\n",
    "    Date=i.text\n",
    "    DATE.append(Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35cbb213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['June 17, 2016',\n",
       " 'January 12, 2017',\n",
       " 'October 8, 2016',\n",
       " 'May 2, 2018',\n",
       " 'January 30, 2017',\n",
       " 'April 6, 2015',\n",
       " 'May 24, 2018',\n",
       " 'March 6, 2014',\n",
       " 'November 19, 2014',\n",
       " 'February 27, 2018',\n",
       " 'July 15, 2012',\n",
       " 'January 31, 2012',\n",
       " 'April 5, 2018',\n",
       " 'June 16, 2009',\n",
       " 'January 14, 2015',\n",
       " 'May 31, 2013',\n",
       " 'June 25, 2018',\n",
       " 'September 5, 2013',\n",
       " 'June 14, 2018',\n",
       " 'June 4, 2010',\n",
       " 'October 22, 2015',\n",
       " 'October 7, 2014',\n",
       " 'January 26, 2018',\n",
       " 'May 10, 2011',\n",
       " 'February 20, 2014',\n",
       " 'November 9, 2017',\n",
       " 'July 25, 2012',\n",
       " 'December 3, 2015',\n",
       " 'May 31, 2018',\n",
       " 'March 22, 2015']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b24c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEW = []\n",
    "View=driver.find_elements(By.XPATH, \"(//table[contains(@class,'wikitable')])[1]/tbody/tr/td[3]\")\n",
    "for i in View:\n",
    "    View=i.text\n",
    "    VIEW.append(View)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1cbe3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14.09',\n",
       " '8.38',\n",
       " '6.87',\n",
       " '6.62',\n",
       " '6.20',\n",
       " '6.17',\n",
       " '5.88',\n",
       " '5.70',\n",
       " '5.15',\n",
       " '5.07',\n",
       " '5.05',\n",
       " '4.58',\n",
       " '4.55',\n",
       " '4.34',\n",
       " '4.00',\n",
       " '3.97',\n",
       " '3.96',\n",
       " '3.96',\n",
       " '3.91',\n",
       " '3.85',\n",
       " '3.77',\n",
       " '3.73',\n",
       " '3.73',\n",
       " '3.69',\n",
       " '3.67',\n",
       " '3.67',\n",
       " '3.61',\n",
       " '3.59',\n",
       " '3.56',\n",
       " '3.55']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e213d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b2ae2b6",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series B) Place C) Date D) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1227c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome();\n",
    "driver.get(\"http://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcf1f4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATCHES = []\n",
    "Matches=driver.find_elements(By.XPATH, '//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in Matches:\n",
    "    Matches=i.text\n",
    "    MATCHES.append(Matches)\n",
    "MATCHES    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "512ba5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Himachal Pradesh Cricket Association Stadium,',\n",
       " 'Harare Sports Club,',\n",
       " 'Harare Sports Club,',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PLACE = []\n",
    "Place=driver.find_elements(By.XPATH, '//span[@class=\"ng-binding ng-scope\"]')\n",
    "for i in Place:\n",
    "    Place=i.text\n",
    "    PLACE.append(Place)\n",
    "PLACE    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ffe6e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9:30 AM IST', '8:00 PM IST', '', '', '', '']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME = []\n",
    "Time=driver.find_elements(By.XPATH, '//div[@class=\"match-time ng-binding\"]')\n",
    "for i in Time:\n",
    "    Time=i.text\n",
    "    TIME.append(Time)\n",
    "TIME    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd19d91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7 March, 2024',\n",
       " '6 July, 2024',\n",
       " '7 July, 2024',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATE = []\n",
    "Date=driver.find_elements(By.XPATH, '//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in Date:\n",
    "    Date=i.text\n",
    "    DATE.append(Date)\n",
    "DATE    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1529a6",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10461b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome();\n",
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfc4359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_menu = driver.find_element(By.XPATH, \"//button[contains(text(),'Open Source')]\")\n",
    "explore_menu.click()\n",
    "\n",
    "trending_option = driver.find_element(By.XPATH, \"(//a[contains(text(),'Trending')])[1]\")\n",
    "trending_option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24d309fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['google / gemma_pytorch',\n",
       " 'google / gemma.cpp',\n",
       " 'SoraWebui / SoraWebui',\n",
       " 'zed-industries / zed',\n",
       " 'facebook / react-strict-dom',\n",
       " 'all-in-aigc / sorafm',\n",
       " 'jackfrued / Python-100-Days',\n",
       " 'levihsu / OOTDiffusion',\n",
       " 'FujiwaraChoki / MoneyPrinterV2',\n",
       " 'mtkarimi / smart-resident-guard',\n",
       " 'localsend / localsend',\n",
       " 'xiaolai / everyone-can-use-english',\n",
       " 'google-deepmind / gemma',\n",
       " 'zhayujie / chatgpt-on-wechat',\n",
       " 'lobehub / lobe-chat',\n",
       " 'soufianetahiri / Anxun-isoon',\n",
       " 'weijunext / indie-hacker-tools',\n",
       " 'keep-starknet-strange / awesome-starknet',\n",
       " 'facebook / react-native',\n",
       " 'open-telemetry / opentelemetry-cpp',\n",
       " 'songquanpeng / one-api',\n",
       " 'ollama / ollama',\n",
       " 'lencx / Noi',\n",
       " 'starknet-io / provisions-data',\n",
       " 'Azure-Samples / azure-search-openai-demo']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPONAME = []\n",
    "RepoName=driver.find_elements(By.XPATH, \"//h2[@class='h3 lh-condensed']\")\n",
    "for i in RepoName:\n",
    "    RepoName=i.text\n",
    "    REPONAME.append(RepoName)\n",
    "REPONAME  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8e092da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The official PyTorch implementation of Google's Gemma models\",\n",
       " \"lightweight, standalone C++ inference engine for Google's Gemma models.\",\n",
       " \"SoraWebui is an open-source Sora web client, enabling users to easily create videos from text with OpenAI's Sora model.\",\n",
       " 'Code at the speed of thought – Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.',\n",
       " 'React Strict DOM (RSD) is a subset of React DOM, imperative DOM, and CSS that supports web and native targets',\n",
       " 'Sora AI Video Generator by Sora.FM',\n",
       " 'Python - 100天从新手到大师',\n",
       " 'Official implementation of OOTDiffusion: Outfitting Fusion based Latent Diffusion for Controllable Virtual Try-on',\n",
       " 'Automate the process of making money online.',\n",
       " 'An open-source cross-platform alternative to AirDrop',\n",
       " '人人都能用英语',\n",
       " 'Open weights LLM from Google DeepMind.',\n",
       " '基于大模型搭建的微信聊天机器人，同时支持微信、企业微信、公众号、飞书、钉钉接入，可选择GPT3.5/GPT4.0/Claude/文心一言/讯飞星火/通义千问/Gemini/GLM-4/LinkAI，能处理文本、语音和图片，访问操作系统和互联网，支持基于自有知识库进行定制企业智能客服。',\n",
       " '🤯 Lobe Chat - an open-source, modern-design ChatGPT/LLMs UI/Framework. Supports speech-synthesis, multi-modal, and extensible plugin system. One-click FREE deployment of your private ChatGPT/Gemini/Ollama chat application.',\n",
       " 'I-SOON/Anxun leak related stuff',\n",
       " '收录独立开发者出海技术栈和工具',\n",
       " 'A curated list of awesome StarkNet resources, libraries, tools and more',\n",
       " 'A framework for building native applications using React',\n",
       " 'The OpenTelemetry C++ Client',\n",
       " 'OpenAI 接口管理 & 分发系统，支持 Azure、Anthropic Claude、Google PaLM 2 & Gemini、智谱 ChatGLM、百度文心一言、讯飞星火认知、阿里通义千问、360 智脑以及腾讯混元，可用于二次分发管理 key，仅单可执行文件，已打包好 Docker 镜像，一键部署，开箱即用. OpenAI key management & redistribution system, using a single API for all LLMs, and features an English UI.',\n",
       " 'Get up and running with Llama 2, Mistral, Gemma, and other large language models.',\n",
       " '🚀 Power Your World with AI - Explore, Extend, Empower.',\n",
       " 'Lists of eligible identities for Starknet provisions.',\n",
       " 'A sample app for the Retrieval-Augmented Generation pattern running in Azure, using Azure AI Search for retrieval and Azure OpenAI large language models to power ChatGPT-style and Q&A experiences.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPODETAILS = []\n",
    "RepoDetails=driver.find_elements(By.XPATH, '//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in RepoDetails:\n",
    "    RepoDetails=i.text\n",
    "    REPODETAILS.append(RepoDetails)\n",
    "REPODETAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "640c90cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,193',\n",
       " '135',\n",
       " '1,497',\n",
       " '86',\n",
       " '588',\n",
       " '151',\n",
       " '24,876',\n",
       " '882',\n",
       " '1,658',\n",
       " '44',\n",
       " '348',\n",
       " '114',\n",
       " '146,965',\n",
       " '50,748',\n",
       " '1,699',\n",
       " '205',\n",
       " '961',\n",
       " '108',\n",
       " '237',\n",
       " '64',\n",
       " '28,785',\n",
       " '1,379',\n",
       " '17,847',\n",
       " '2,936',\n",
       " '772',\n",
       " '78',\n",
       " '22,054',\n",
       " '6,102',\n",
       " '20,108',\n",
       " '3,950',\n",
       " '99',\n",
       " '51',\n",
       " '1,697',\n",
       " '132',\n",
       " '1,307',\n",
       " '262',\n",
       " '114,647',\n",
       " '23,702',\n",
       " '650',\n",
       " '335',\n",
       " '10,138',\n",
       " '2,390',\n",
       " '39,560',\n",
       " '2,442',\n",
       " '1,931',\n",
       " '92',\n",
       " '115',\n",
       " '42',\n",
       " '4,862',\n",
       " '2,944']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COUNT = []\n",
    "Count=driver.find_elements(By.XPATH, '//a[@class=\"Link Link--muted d-inline-block mr-3\"]')\n",
    "for i in Count:\n",
    "    Count=i.text\n",
    "    COUNT.append(Count)\n",
    "COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56e356e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'C++',\n",
       " 'TypeScript',\n",
       " 'Rust',\n",
       " 'JavaScript',\n",
       " 'TypeScript',\n",
       " 'Python',\n",
       " 'Python',\n",
       " 'Python',\n",
       " 'Python',\n",
       " 'Dart',\n",
       " 'Jupyter Notebook',\n",
       " 'Jupyter Notebook',\n",
       " 'Python',\n",
       " 'TypeScript',\n",
       " 'Python',\n",
       " 'C++',\n",
       " 'C++',\n",
       " 'JavaScript',\n",
       " 'Go',\n",
       " 'JavaScript',\n",
       " 'Python']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANGUAGE = []\n",
    "Language=driver.find_elements(By.XPATH, '//span[@itemprop=\"programmingLanguage\"]')\n",
    "for i in Language:\n",
    "    Language=i.text\n",
    "    LANGUAGE.append(Language)\n",
    "LANGUAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d5667a",
   "metadata": {},
   "source": [
    "# 5 Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the\n",
    "following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9da7ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome();\n",
    "driver.get(\"https://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu100 = driver.find_element(By.XPATH, \"(//*[@class='c-icon   lrv-u-color-black lrv-u-margin-lr-100 lrv-u-margin-t-025 u-color-white@desktop u-height-30 u-width-30 u-width-23@mobile-max'])[1]\")\n",
    "menu100.click()\n",
    "\n",
    "Bill100 = driver.find_element(By.XPATH, \"//a[contains(text(),'Billboard Hot 100™')]\")\n",
    "Bill100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b1d0fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lovin On Me']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MUSICNAME = []\n",
    "MusicName=driver.find_elements(By.XPATH, '//h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet\"]')\n",
    "for i in MusicName:\n",
    "    MusicName=i.text\n",
    "    MUSICNAME.append(MusicName)\n",
    "MUSICNAME  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9b5325d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jack Harlow']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARTIST = []\n",
    "Artist=driver.find_elements(By.XPATH, '//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\"]')\n",
    "for i in Artist:\n",
    "    Artist=i.text\n",
    "    ARTIST.append(Artist)\n",
    "ARTIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8224456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8501d568",
   "metadata": {},
   "source": [
    "# 6.Scrape the details of Highest selling novels.\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6aafe8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome();\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eaa369ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Da Vinci Code,The',\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Harry Potter and the Chamber of Secrets',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " 'Angels and Demons',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Fifty Shades Darker',\n",
       " 'Twilight',\n",
       " 'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       " 'Fifty Shades Freed',\n",
       " 'Lost Symbol,The',\n",
       " 'New Moon',\n",
       " 'Deception Point',\n",
       " 'Eclipse',\n",
       " 'Lovely Bones,The',\n",
       " 'Curious Incident of the Dog in the Night-time,The',\n",
       " 'Digital Fortress',\n",
       " 'Short History of Nearly Everything,A',\n",
       " 'Girl Who Played with Fire,The:Millennium Trilogy',\n",
       " 'Breaking Dawn',\n",
       " 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar',\n",
       " 'Gruffalo,The',\n",
       " \"Jamie's 30-Minute Meals\",\n",
       " 'Kite Runner,The',\n",
       " 'One Day',\n",
       " 'Thousand Splendid Suns,A',\n",
       " \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\",\n",
       " \"Time Traveler's Wife,The\",\n",
       " 'Atonement',\n",
       " \"Bridget Jones's Diary:A Novel\",\n",
       " 'World According to Clarkson,The',\n",
       " \"Captain Corelli's Mandolin\",\n",
       " 'Sound of Laughter,The',\n",
       " 'Life of Pi',\n",
       " 'Billy Connolly',\n",
       " 'Child Called It,A',\n",
       " \"Gruffalo's Child,The\",\n",
       " \"Angela's Ashes:A Memoir of a Childhood\",\n",
       " 'Birdsong',\n",
       " 'Northern Lights:His Dark Materials S.',\n",
       " 'Labyrinth',\n",
       " 'Harry Potter and the Half-blood Prince',\n",
       " 'Help,The',\n",
       " 'Man and Boy',\n",
       " 'Memoirs of a Geisha',\n",
       " \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       " 'Island,The',\n",
       " 'PS, I Love You',\n",
       " 'You are What You Eat:The Plan That Will Change Your Life',\n",
       " 'Shadow of the Wind,The',\n",
       " 'Tales of Beedle the Bard,The',\n",
       " 'Broker,The',\n",
       " \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\",\n",
       " 'Subtle Knife,The:His Dark Materials S.',\n",
       " 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation',\n",
       " \"Delia's How to Cook:(Bk.1)\",\n",
       " 'Chocolat',\n",
       " 'Boy in the Striped Pyjamas,The',\n",
       " \"My Sister's Keeper\",\n",
       " 'Amber Spyglass,The:His Dark Materials S.',\n",
       " 'To Kill a Mockingbird',\n",
       " 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       " 'Dear Fatty',\n",
       " 'Short History of Tractors in Ukrainian,A',\n",
       " 'Hannibal',\n",
       " 'Lord of the Rings,The',\n",
       " 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio',\n",
       " 'Interpretation of Murder,The',\n",
       " 'Sharon Osbourne Extreme:My Autobiography',\n",
       " 'Alchemist,The:A Fable About Following Your Dream',\n",
       " \"At My Mother's Knee ...:and Other Low Joints\",\n",
       " 'Notes from a Small Island',\n",
       " 'Return of the Naked Chef,The',\n",
       " 'Bridget Jones: The Edge of Reason',\n",
       " \"Jamie's Italy\",\n",
       " 'I Can Make You Thin',\n",
       " 'Down Under',\n",
       " 'Summons,The',\n",
       " 'Small Island',\n",
       " 'Nigella Express',\n",
       " 'Brick Lane',\n",
       " \"Memory Keeper's Daughter,The\",\n",
       " 'Room on the Broom',\n",
       " 'About a Boy',\n",
       " 'My Booky Wook',\n",
       " 'God Delusion,The',\n",
       " '\"Beano\" Annual,The',\n",
       " 'White Teeth',\n",
       " 'House at Riverton,The',\n",
       " 'Book Thief,The',\n",
       " 'Nights of Rain and Stars',\n",
       " 'Ghost,The',\n",
       " 'Happy Days with the Naked Chef',\n",
       " 'Hunger Games,The:Hunger Games Trilogy',\n",
       " \"Lost Boy,The:A Foster Child's Search for the Love of a Family\",\n",
       " \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAME = []\n",
    "Name=driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']/tbody/tr/td[2]\")\n",
    "for i in Name:\n",
    "    Name=i.text\n",
    "    NAME.append(Name)\n",
    "NAME  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89de3919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '50',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '60',\n",
       " '61',\n",
       " '62',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '70',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '74',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '80',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '90',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " '100']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANK = []\n",
    "Rank=driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']/tbody/tr/td[1]\")\n",
    "for i in Rank:\n",
    "    Rank=i.text\n",
    "    RANK.append(Rank)\n",
    "RANK  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfb217be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Meyer, Stephenie',\n",
       " 'Larsson, Stieg',\n",
       " 'James, E. L.',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Sebold, Alice',\n",
       " 'Haddon, Mark',\n",
       " 'Brown, Dan',\n",
       " 'Bryson, Bill',\n",
       " 'Larsson, Stieg',\n",
       " 'Meyer, Stephenie',\n",
       " 'Carle, Eric',\n",
       " 'Donaldson, Julia',\n",
       " 'Oliver, Jamie',\n",
       " 'Hosseini, Khaled',\n",
       " 'Nicholls, David',\n",
       " 'Hosseini, Khaled',\n",
       " 'Larsson, Stieg',\n",
       " 'Niffenegger, Audrey',\n",
       " 'McEwan, Ian',\n",
       " 'Fielding, Helen',\n",
       " 'Clarkson, Jeremy',\n",
       " 'Bernieres, Louis de',\n",
       " 'Kay, Peter',\n",
       " 'Martel, Yann',\n",
       " 'Stephenson, Pamela',\n",
       " 'Pelzer, Dave',\n",
       " 'Donaldson, Julia',\n",
       " 'McCourt, Frank',\n",
       " 'Faulks, Sebastian',\n",
       " 'Pullman, Philip',\n",
       " 'Mosse, Kate',\n",
       " 'Rowling, J.K.',\n",
       " 'Stockett, Kathryn',\n",
       " 'Parsons, Tony',\n",
       " 'Golden, Arthur',\n",
       " 'McCall Smith, Alexander',\n",
       " 'Hislop, Victoria',\n",
       " 'Ahern, Cecelia',\n",
       " 'McKeith, Gillian',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " 'Rowling, J.K.',\n",
       " 'Grisham, John',\n",
       " 'Atkins, Robert C.',\n",
       " 'Pullman, Philip',\n",
       " 'Truss, Lynne',\n",
       " 'Smith, Delia',\n",
       " 'Harris, Joanne',\n",
       " 'Boyne, John',\n",
       " 'Picoult, Jodi',\n",
       " 'Pullman, Philip',\n",
       " 'Lee, Harper',\n",
       " 'Gray, John',\n",
       " 'French, Dawn',\n",
       " 'Lewycka, Marina',\n",
       " 'Harris, Thomas',\n",
       " 'Tolkien, J. R. R.',\n",
       " 'Moore, Michael',\n",
       " 'Rubenfeld, Jed',\n",
       " 'Osbourne, Sharon',\n",
       " 'Coelho, Paulo',\n",
       " \"O'Grady, Paul\",\n",
       " 'Bryson, Bill',\n",
       " 'Oliver, Jamie',\n",
       " 'Fielding, Helen',\n",
       " 'Oliver, Jamie',\n",
       " 'McKenna, Paul',\n",
       " 'Bryson, Bill',\n",
       " 'Grisham, John',\n",
       " 'Levy, Andrea',\n",
       " 'Lawson, Nigella',\n",
       " 'Ali, Monica',\n",
       " 'Edwards, Kim',\n",
       " 'Donaldson, Julia',\n",
       " 'Hornby, Nick',\n",
       " 'Brand, Russell',\n",
       " 'Dawkins, Richard',\n",
       " '0',\n",
       " 'Smith, Zadie',\n",
       " 'Morton, Kate',\n",
       " 'Zusak, Markus',\n",
       " 'Binchy, Maeve',\n",
       " 'Harris, Robert',\n",
       " 'Oliver, Jamie',\n",
       " 'Collins, Suzanne',\n",
       " 'Pelzer, Dave',\n",
       " 'Oliver, Jamie']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AuthorName = []\n",
    "Aname=driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']/tbody/tr/td[3]\")\n",
    "for i in Aname:\n",
    "    Aname=i.text\n",
    "    AuthorName.append(Aname)\n",
    "AuthorName  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88da137c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5,094,805',\n",
       " '4,475,152',\n",
       " '4,200,654',\n",
       " '4,179,479',\n",
       " '3,758,936',\n",
       " '3,583,215',\n",
       " '3,484,047',\n",
       " '3,377,906',\n",
       " '3,193,946',\n",
       " '2,950,264',\n",
       " '2,479,784',\n",
       " '2,315,405',\n",
       " '2,233,570',\n",
       " '2,193,928',\n",
       " '2,183,031',\n",
       " '2,152,737',\n",
       " '2,062,145',\n",
       " '2,052,876',\n",
       " '2,005,598',\n",
       " '1,979,552',\n",
       " '1,928,900',\n",
       " '1,852,919',\n",
       " '1,814,784',\n",
       " '1,787,118',\n",
       " '1,783,535',\n",
       " '1,781,269',\n",
       " '1,743,266',\n",
       " '1,629,119',\n",
       " '1,616,068',\n",
       " '1,583,992',\n",
       " '1,555,135',\n",
       " '1,546,886',\n",
       " '1,539,428',\n",
       " '1,508,205',\n",
       " '1,489,403',\n",
       " '1,352,318',\n",
       " '1,310,207',\n",
       " '1,310,176',\n",
       " '1,231,957',\n",
       " '1,217,712',\n",
       " '1,208,711',\n",
       " '1,204,058',\n",
       " '1,184,967',\n",
       " '1,181,503',\n",
       " '1,181,093',\n",
       " '1,153,181',\n",
       " '1,132,336',\n",
       " '1,130,802',\n",
       " '1,126,337',\n",
       " '1,115,549',\n",
       " '1,108,328',\n",
       " '1,107,379',\n",
       " '1,104,403',\n",
       " '1,092,349',\n",
       " '1,090,847',\n",
       " '1,087,262',\n",
       " '1,054,196',\n",
       " '1,037,160',\n",
       " '1,023,688',\n",
       " '1,015,956',\n",
       " '1,009,873',\n",
       " '1,004,414',\n",
       " '1,003,780',\n",
       " '1,002,314',\n",
       " '998,213',\n",
       " '992,846',\n",
       " '986,753',\n",
       " '986,115',\n",
       " '970,509',\n",
       " '967,466',\n",
       " '963,353',\n",
       " '962,515',\n",
       " '959,496',\n",
       " '956,114',\n",
       " '945,640',\n",
       " '931,312',\n",
       " '925,425',\n",
       " '924,695',\n",
       " '906,968',\n",
       " '905,086',\n",
       " '890,847',\n",
       " '869,671',\n",
       " '869,659',\n",
       " '862,602',\n",
       " '856,540',\n",
       " '845,858',\n",
       " '842,535',\n",
       " '828,215',\n",
       " '820,563',\n",
       " '816,907',\n",
       " '816,585',\n",
       " '815,586',\n",
       " '814,370',\n",
       " '809,641',\n",
       " '808,900',\n",
       " '807,311',\n",
       " '794,201',\n",
       " '792,187',\n",
       " '791,507',\n",
       " '791,095']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOLD = []\n",
    "Sold=driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']/tbody/tr/td[4]\")\n",
    "for i in Sold:\n",
    "    Sold=i.text\n",
    "    SOLD.append(Sold)\n",
    "SOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b293fbc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Pan Macmillan',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Quercus',\n",
       " 'Little, Brown Book',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Bloomsbury',\n",
       " 'Hodder & Stoughton',\n",
       " 'Bloomsbury',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Canongate',\n",
       " 'HarperCollins',\n",
       " 'Orion',\n",
       " 'Pan Macmillan',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Penguin',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Headline',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Profile Books Group',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Random House Childrens Books G',\n",
       " 'Hodder & Stoughton',\n",
       " 'Scholastic Ltd.',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Headline',\n",
       " 'Little, Brown Book',\n",
       " 'HarperCollins',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Random House',\n",
       " 'Headline',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Hodder & Stoughton',\n",
       " 'Transworld',\n",
       " 'D.C. Thomson',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Transworld',\n",
       " 'Orion',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Penguin']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PUBLISTER = []\n",
    "Publisher=driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']/tbody/tr/td[5]\")\n",
    "for i in Publisher:\n",
    "    Publisher=i.text\n",
    "    PUBLISTER.append(Publisher)\n",
    "PUBLISTER  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b2e6028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Romance & Sagas',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Popular Science',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Picture Books',\n",
       " 'Picture Books',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Humour: Collections & General',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Biography: The Arts',\n",
       " 'Autobiography: General',\n",
       " 'Picture Books',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Fitness & Diet',\n",
       " 'General & Literary Fiction',\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Fitness & Diet',\n",
       " 'Young Adult Fiction',\n",
       " 'Usage & Writing Guides',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Popular Culture & Media: General Interest',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'Current Affairs & Issues',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Travel Writing',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'National & Regional Cuisine',\n",
       " 'Fitness & Diet',\n",
       " 'Travel Writing',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Picture Books',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Popular Science',\n",
       " \"Children's Annuals\",\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'Young Adult Fiction',\n",
       " 'Biography: General',\n",
       " 'Food & Drink: General']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GENERS = []\n",
    "Geners=driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']/tbody/tr/td[6]\")\n",
    "for i in Geners:\n",
    "    Geners=i.text\n",
    "    GENERS.append(Geners)\n",
    "GENERS  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee2b66",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have\n",
    "to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fa46f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome();\n",
    "driver.get(\"https://www.imdb.com/search/title/?title_type=tv_series&sort=num_votes,desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d06acc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Game of Thrones',\n",
       " '2. Breaking Bad',\n",
       " '3. Stranger Things',\n",
       " '4. Friends',\n",
       " '5. The Walking Dead',\n",
       " '6. Sherlock',\n",
       " '7. The Big Bang Theory',\n",
       " '8. Dexter',\n",
       " '9. How I Met Your Mother',\n",
       " '10. The Office',\n",
       " '11. True Detective',\n",
       " '12. Peaky Blinders',\n",
       " '13. Better Call Saul',\n",
       " '14. The Boys',\n",
       " '15. Black Mirror',\n",
       " '16. Rick and Morty',\n",
       " '17. Lost',\n",
       " '18. The Mandalorian',\n",
       " '19. Vikings',\n",
       " '20. Prison Break',\n",
       " '21. The Witcher',\n",
       " '22. Squid Game',\n",
       " '23. Westworld',\n",
       " '24. House of Cards',\n",
       " '25. Money Heist',\n",
       " '26. House',\n",
       " '27. The Last of Us',\n",
       " '28. Attack on Titan',\n",
       " '29. Supernatural',\n",
       " '30. Modern Family',\n",
       " '31. Suits',\n",
       " '32. Daredevil',\n",
       " '33. Narcos',\n",
       " '34. The Sopranos',\n",
       " '35. Arrow',\n",
       " '36. Dark',\n",
       " '37. The Simpsons',\n",
       " '38. Fargo',\n",
       " '39. Mr. Robot',\n",
       " '40. Loki',\n",
       " '41. South Park',\n",
       " '42. The Wire',\n",
       " '43. Death Note',\n",
       " '44. The Flash',\n",
       " '45. House of the Dragon',\n",
       " '46. Family Guy',\n",
       " '47. Homeland',\n",
       " '48. Avatar: The Last Airbender',\n",
       " '49. Brooklyn Nine-Nine',\n",
       " '50. Wednesday',\n",
       " 'Recently viewed']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOVIENAME = []\n",
    "MovieName=driver.find_elements(By.XPATH, '//h3[@class=\"ipc-title__text\"]')\n",
    "for i in MovieName:\n",
    "    MovieName=i.text\n",
    "    MOVIENAME.append(MovieName)\n",
    "MOVIENAME  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d846ec58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2011–2019',\n",
       " 'TV-MA',\n",
       " '2008–2013',\n",
       " 'TV-MA',\n",
       " '2016–2025',\n",
       " 'TV-14',\n",
       " '1994–2004',\n",
       " 'TV-14',\n",
       " '2010–2022',\n",
       " 'TV-MA',\n",
       " '2010–2017',\n",
       " 'TV-14',\n",
       " '2007–2019',\n",
       " 'TV-PG',\n",
       " '2006–2013',\n",
       " 'TV-MA',\n",
       " '2005–2014',\n",
       " 'TV-14',\n",
       " '2005–2013',\n",
       " 'TV-14',\n",
       " '2014–',\n",
       " 'TV-MA',\n",
       " '2013–2022',\n",
       " 'TV-MA',\n",
       " '2015–2022',\n",
       " 'TV-MA',\n",
       " '2019–',\n",
       " 'TV-MA',\n",
       " '2011–',\n",
       " 'TV-MA',\n",
       " '2013–',\n",
       " 'TV-MA',\n",
       " '2004–2010',\n",
       " 'TV-14',\n",
       " '2019–',\n",
       " 'TV-14',\n",
       " '2013–2020',\n",
       " 'TV-MA',\n",
       " '2005–2017',\n",
       " 'TV-14',\n",
       " '2019–',\n",
       " 'TV-MA',\n",
       " '2021–',\n",
       " 'TV-MA',\n",
       " '2016–2022',\n",
       " 'TV-MA',\n",
       " '2013–2018',\n",
       " 'TV-MA',\n",
       " '2017–2021',\n",
       " 'TV-MA',\n",
       " '2004–2012',\n",
       " 'TV-14',\n",
       " '2023–',\n",
       " 'TV-MA',\n",
       " '2013–2023',\n",
       " 'TV-MA',\n",
       " '2005–2020',\n",
       " 'TV-14',\n",
       " '2009–2020',\n",
       " 'TV-PG',\n",
       " '2011–2019',\n",
       " 'TV-14',\n",
       " '2015–2018',\n",
       " 'TV-MA',\n",
       " '2015–2017',\n",
       " 'TV-MA',\n",
       " '1999–2007',\n",
       " 'TV-MA',\n",
       " '2012–2020',\n",
       " 'TV-14',\n",
       " '2017–2020',\n",
       " 'TV-MA',\n",
       " '1989–',\n",
       " 'TV-14',\n",
       " '2014–2024',\n",
       " 'TV-MA',\n",
       " '2015–2019',\n",
       " 'TV-MA',\n",
       " '2021–2023',\n",
       " 'TV-14',\n",
       " '1997–',\n",
       " 'TV-MA',\n",
       " '2002–2008',\n",
       " 'TV-MA',\n",
       " '2006–2007',\n",
       " 'TV-14',\n",
       " '2014–2023',\n",
       " 'TV-PG',\n",
       " '2022–',\n",
       " 'TV-MA',\n",
       " '1999–2025',\n",
       " 'TV-MA',\n",
       " '2011–2020',\n",
       " 'TV-MA',\n",
       " '2005–2008',\n",
       " 'TV-Y7-FV',\n",
       " '2013–2021',\n",
       " 'TV-14',\n",
       " '2022–',\n",
       " 'TV-14']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YEAR =[]\n",
    "Year=driver.find_elements(By.XPATH, '//span[@class=\"sc-be6f1408-8 fcCUPU dli-title-metadata-item\"]')\n",
    "for i in Year:\n",
    "    Year=i.text\n",
    "    YEAR.append(Year)\n",
    "YEAR    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "806ed037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2\\n (2.3M)',\n",
       " '9.5\\n (2.1M)',\n",
       " '8.7\\n (1.3M)',\n",
       " '8.9\\n (1.1M)',\n",
       " '8.1\\n (1.1M)',\n",
       " '9.1\\n (988K)',\n",
       " '8.1\\n (860K)',\n",
       " '8.7\\n (759K)',\n",
       " '8.3\\n (723K)',\n",
       " '9.0\\n (699K)',\n",
       " '8.9\\n (642K)',\n",
       " '8.8\\n (636K)',\n",
       " '9.0\\n (636K)',\n",
       " '8.7\\n (634K)',\n",
       " '8.7\\n (632K)',\n",
       " '9.1\\n (594K)',\n",
       " '8.3\\n (590K)',\n",
       " '8.7\\n (580K)',\n",
       " '8.5\\n (575K)',\n",
       " '8.3\\n (574K)',\n",
       " '8.0\\n (565K)',\n",
       " '8.0\\n (530K)',\n",
       " '8.5\\n (529K)',\n",
       " '8.6\\n (528K)',\n",
       " '8.2\\n (526K)',\n",
       " '8.7\\n (504K)',\n",
       " '8.8\\n (501K)',\n",
       " '9.1\\n (498K)',\n",
       " '8.4\\n (479K)',\n",
       " '8.5\\n (476K)',\n",
       " '8.4\\n (471K)',\n",
       " '8.6\\n (471K)',\n",
       " '8.8\\n (465K)',\n",
       " '9.2\\n (462K)',\n",
       " '7.5\\n (445K)',\n",
       " '8.7\\n (437K)',\n",
       " '8.7\\n (433K)',\n",
       " '8.9\\n (416K)',\n",
       " '8.5\\n (415K)',\n",
       " '8.2\\n (406K)',\n",
       " '8.7\\n (403K)',\n",
       " '9.3\\n (373K)',\n",
       " '8.9\\n (372K)',\n",
       " '7.5\\n (367K)',\n",
       " '8.4\\n (363K)',\n",
       " '8.2\\n (362K)',\n",
       " '8.3\\n (359K)',\n",
       " '9.3\\n (357K)',\n",
       " '8.4\\n (356K)',\n",
       " '8.1\\n (353K)']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RATING = []\n",
    "Rating=driver.find_elements(By.XPATH, '//span[@class=\"ipc-rating-star ipc-rating-star--base ipc-rating-star--imdb ratingGroup--imdb-rating\"]')\n",
    "for i in Rating:\n",
    "    Rating=i.text\n",
    "    RATING.append(Rating)\n",
    "RATING  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "981df431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' (2.3M)',\n",
       " ' (2.1M)',\n",
       " ' (1.3M)',\n",
       " ' (1.1M)',\n",
       " ' (1.1M)',\n",
       " ' (988K)',\n",
       " ' (860K)',\n",
       " ' (759K)',\n",
       " ' (723K)',\n",
       " ' (699K)',\n",
       " ' (642K)',\n",
       " ' (636K)',\n",
       " ' (636K)',\n",
       " ' (634K)',\n",
       " ' (632K)',\n",
       " ' (594K)',\n",
       " ' (590K)',\n",
       " ' (580K)',\n",
       " ' (575K)',\n",
       " ' (574K)',\n",
       " ' (565K)',\n",
       " ' (530K)',\n",
       " ' (529K)',\n",
       " ' (528K)',\n",
       " ' (526K)',\n",
       " ' (504K)',\n",
       " ' (501K)',\n",
       " ' (498K)',\n",
       " ' (479K)',\n",
       " ' (476K)',\n",
       " ' (471K)',\n",
       " ' (471K)',\n",
       " ' (465K)',\n",
       " ' (462K)',\n",
       " ' (445K)',\n",
       " ' (437K)',\n",
       " ' (433K)',\n",
       " ' (416K)',\n",
       " ' (415K)',\n",
       " ' (406K)',\n",
       " ' (403K)',\n",
       " ' (373K)',\n",
       " ' (372K)',\n",
       " ' (367K)',\n",
       " ' (363K)',\n",
       " ' (362K)',\n",
       " ' (359K)',\n",
       " ' (357K)',\n",
       " ' (356K)',\n",
       " ' (353K)']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOTES = []\n",
    "Votes=driver.find_elements(By.XPATH, '//span[@class=\"ipc-rating-star--voteCount\"]')\n",
    "for i in Votes:\n",
    "    Votes=i.text\n",
    "    VOTES.append(Votes)\n",
    "VOTES  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350e59c5",
   "metadata": {},
   "source": [
    "# 8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You\n",
    "have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23843859",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome();\n",
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81998a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iris',\n",
       " 'Dry Bean Dataset',\n",
       " 'Heart Disease',\n",
       " 'Rice (Cammeo and Osmancik)',\n",
       " 'Adult',\n",
       " 'Raisin',\n",
       " 'RT-IoT2022',\n",
       " 'Regensburg Pediatric Appendicitis',\n",
       " 'National Poll on Healthy Aging (NPHA)',\n",
       " 'Infrared Thermography Temperature',\n",
       " 'Jute Pest',\n",
       " 'Differentiated Thyroid Cancer Recurrence']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPONAME1 = []\n",
    "Reponame1=driver.find_elements(By.XPATH, '//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for i in Reponame1:\n",
    "    Reponame1=i.text\n",
    "    REPONAME1.append(Reponame1)\n",
    "REPONAME1  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "997e9f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classification',\n",
       " '150 Instances',\n",
       " '4 Features',\n",
       " 'Classification',\n",
       " '13.61K Instances',\n",
       " '16 Features',\n",
       " 'Classification',\n",
       " '303 Instances',\n",
       " '13 Features',\n",
       " 'Classification',\n",
       " '3.81K Instances',\n",
       " '7 Features',\n",
       " 'Classification',\n",
       " '48.84K Instances',\n",
       " '14 Features',\n",
       " 'Classification',\n",
       " '900 Instances',\n",
       " '8 Features',\n",
       " 'Classification, Regression, Clustering',\n",
       " '123.12K Instances',\n",
       " '84 Features',\n",
       " 'Classification',\n",
       " '782 Instances',\n",
       " '59 Features',\n",
       " 'Classification',\n",
       " '714 Instances',\n",
       " '15 Features',\n",
       " 'Regression',\n",
       " '1.02K Instances',\n",
       " '33 Features',\n",
       " 'Classification, Other',\n",
       " '7.24K Instances',\n",
       " '17 Features',\n",
       " 'Classification',\n",
       " '383 Instances',\n",
       " '16 Features']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATATYPE = []\n",
    "dataType=driver.find_elements(By.XPATH, '//span[@class=\"truncate\"]')\n",
    "for i in dataType:\n",
    "    dataType=i.text\n",
    "    DATATYPE.append(dataType)\n",
    "DATATYPE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce62c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
